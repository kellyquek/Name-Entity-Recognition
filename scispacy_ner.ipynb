{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy\n",
    "# pip install scispacy\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_sm-0.2.5.tar.gz\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_lg-0.2.5.tar.gz\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_bionlp13cg_md-0.2.5.tar.gz\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_bc5cdr_md-0.2.5.tar.gz\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_jnlpba_md-0.2.5.tar.gz\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_craft_md-0.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import scispacy\n",
    "import spacy\n",
    "\n",
    "\n",
    "#Core models\n",
    "import en_core_sci_sm\n",
    "import en_core_sci_lg\n",
    "\n",
    "#NER specific models\n",
    "import en_ner_craft_md\n",
    "import en_ner_bc5cdr_md\n",
    "import en_ner_jnlpba_md\n",
    "import en_ner_bionlp13cg_md\n",
    "\n",
    "#Tools for extracting & displaying data\n",
    "from spacy import displacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "nlp_cr = en_ner_craft_md.load()\n",
    "nlp_bc = en_ner_bc5cdr_md.load()\n",
    "nlp_bi = en_ner_bionlp13cg_md.load()\n",
    "nlp_jn = en_ner_jnlpba_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entity/value pairs to table\n",
    "def add_cr(abstractList, doiList):\n",
    "    i = 0\n",
    "    table= {\"doi\":[], \"Entity\":[], \"Class\":[], \"Start\":[], \"End\":[]}\n",
    "    for doc in nlp_cr.pipe(abstractList):\n",
    "        doi = doiList[i]\n",
    "        for x in doc.ents:\n",
    "          table[\"doi\"].append(doi)\n",
    "          table[\"Entity\"].append(x.text)\n",
    "          table[\"Class\"].append(x.label_)\n",
    "          table[\"Start\"].append(x.start_char-x.sent.start_char)\n",
    "          table[\"End\"].append(x.end_char-x.sent.start_char)  \n",
    "        i +=1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bc(abstractList, doiList):\n",
    "    i = 0\n",
    "    table= {\"doi\":[], \"Entity\":[], \"Class\":[], \"Start\":[], \"End\":[]}\n",
    "    for doc in nlp_bc.pipe(abstractList):\n",
    "        doi = doiList[i]\n",
    "        for x in doc.ents:\n",
    "          table[\"doi\"].append(doi)\n",
    "          table[\"Entity\"].append(x.text)\n",
    "          table[\"Class\"].append(x.label_)\n",
    "          table[\"Start\"].append(x.start_char-x.sent.start_char)\n",
    "          table[\"End\"].append(x.end_char-x.sent.start_char)      \n",
    "        i +=1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jn(abstractList, doiList):\n",
    "    i = 0\n",
    "    table= {\"doi\":[], \"Entity\":[], \"Class\":[], \"Start\":[], \"End\":[]}\n",
    "    for doc in nlp_jn.pipe(abstractList):\n",
    "        doi = doiList[i]\n",
    "        for x in doc.ents:\n",
    "          table[\"doi\"].append(doi)\n",
    "          table[\"Entity\"].append(x.text)\n",
    "          table[\"Class\"].append(x.label_)\n",
    "          table[\"Start\"].append(x.start_char-x.sent.start_char)\n",
    "          table[\"End\"].append(x.end_char-x.sent.start_char)    \n",
    "        i +=1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bi(abstractList, doiList):\n",
    "    i = 0\n",
    "    table= {\"doi\":[], \"Entity\":[], \"Class\":[], \"Start\":[], \"End\":[]}\n",
    "    for doc in nlp_bi.pipe(abstractList):\n",
    "        doi = doiList[i]\n",
    "        for x in doc.ents:\n",
    "          table[\"doi\"].append(doi)\n",
    "          table[\"Entity\"].append(x.text)\n",
    "          table[\"Class\"].append(x.label_)\n",
    "          table[\"Start\"].append(x.start_char-x.sent.start_char)\n",
    "          table[\"End\"].append(x.end_char-x.sent.start_char)    \n",
    "        i +=1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in file\n",
    "meta_df = pd.read_csv(\"../data/scispacy_sample.csv\")\n",
    "\n",
    "#Sort out blank abstracts\n",
    "docs = meta_df.dropna(subset=['abstract'])\n",
    "\n",
    "#Create lists\n",
    "doiList = docs['doi'].tolist()\n",
    "abstractList = docs['abstract'].tolist()\n",
    "\n",
    "#Add all entity value pairs to table\n",
    "table = add_cr(abstractList, doiList)\n",
    "\n",
    "table = add_bc(abstractList, doiList)\n",
    "\n",
    "table = add_bi(abstractList, doiList)\n",
    "\n",
    "table = add_jn(abstractList, doiList)\n",
    "\n",
    "#Turn table into an exportable CSV file (returns normalized file of entity/value pairs)\n",
    "trans_docs = pd.DataFrame(table)\n",
    "#trans_docs.to_csv (\"Entity_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}